% Fuzzy Methodology for Authorship Detection

\subsection{Mineração de Texto}

A mineração de texto consiste em extrair informações úteis de dados textuais não estruturados através de técnicas estatísticas e computacionais~\cite{feldman2007}. Neste trabalho, transformamos documentos em vetores de variáveis quantitativas que capturam propriedades estatísticas do estilo de escrita, permitindo a aplicação de sistemas de inferência fuzzy para classificação.

\subsection{Conjunto de Dados e Amostragem Estratificada}

Utilizou-se um conjunto de dados textuais balanceado em português do Brasil contendo 100.000 amostras (50.000 autorais, 50.000 de LLMs), extraídas por \textbf{amostragem estratificada proporcional} de um conjunto maior com 2.331.317 documentos originais provenientes de 5 fontes distintas.

\subsubsection{Fontes de Dados e População}

As fontes de texto autoral incluem: (i) \textbf{BrWaC} (Brazilian Web as Corpus), um grande conjunto web de textos brasileiros coletados da internet; e (ii) \textbf{BoolQ}, contendo passagens de contexto para perguntas booleanas.

As fontes de texto gerado por LLM incluem: (i) \textbf{ShareGPT-Portuguese}, conversas em português geradas por modelos GPT; (ii) \textbf{IMDB Reviews}, resenhas traduzidas para português por modelos de tradução automática neural; e (iii) \textbf{Canarim}, dataset contendo saídas geradas por diversos LLMs em português.

\subsubsection{Critérios de Inclusão e Pré-Processamento}

Os textos foram submetidos aos seguintes critérios de filtragem:

\begin{enumerate}
    \item \textbf{Comprimento mínimo}: 100 caracteres (para garantir amostra estilométrica suficiente)
    \item \textbf{Comprimento máximo}: 10.000 caracteres (para evitar textos excessivamente longos)
    \item \textbf{Segmentação}: textos excedendo 10.000 caracteres foram segmentados em fragmentos de até 10.000 caracteres sem sobreposição
    \item \textbf{Codificação}: UTF-8, com remoção de caracteres de controle não-imprimíveis
\end{enumerate}

\subsubsection{Estratégia de Balanceamento}

O balanceamento de classes foi obtido por \textbf{subamostragem da classe majoritária} e \textbf{sobreamostragem da classe minoritária} em cada estrato (fonte de dados), resultando em proporções exatamente iguais (50\%/50\%). A amostragem estratificada garante que cada fonte contribua proporcionalmente ao tamanho original, preservando a diversidade estilística e reduzindo viés de seleção~\cite{cochran1977}.

A estratificação por fonte é essencial porque diferentes origens apresentam variações estilísticas intrínsecas (por exemplo, conversas vs. artigos formais). Ao manter a proporção de cada fonte, garante-se que o classificador seja avaliado em um conjunto representativo da população original, aumentando a validade externa dos resultados.

\subsection{Características Estilométricas}

Utilizamos 10 características estilométricas extraídas pelo módulo \texttt{src/features.py}, selecionadas por capturarem aspectos complementares da estrutura estatística e lexical dos textos: (1) \texttt{sent\_mean} -- comprimento médio de frase (tendência central); (2) \texttt{sent\_std} -- desvio padrão do comprimento de frase (dispersão sintática); (3) \texttt{sent\_burst} -- coeficiente de variação ($\sigma/\mu$, dispersão relativa); (4) \texttt{ttr} -- relação tipo-token ($V/N$, diversidade lexical); (5) \texttt{herdan\_c} -- C de Herdan ($\log V / \log N$, diversidade normalizada); (6) \texttt{hapax\_prop} -- proporção de hapax legomena (raridade lexical); (7) \texttt{char\_entropy} -- variabilidade da distribuição de caracteres (dispersão medida pela fórmula de Shannon); (8) \texttt{func\_word\_ratio} -- proporção de palavras funcionais (estabilidade lexical, menor variância entre textos); (9) \texttt{first\_person\_ratio} -- proporção de pronomes de primeira pessoa (subjetividade); e (10) \texttt{bigram\_repeat\_ratio} -- proporção de bigramas únicos repetidos (redundância local).

Do ponto de vista estatístico, todas as características são \textbf{variáveis contínuas em escala de razão}, possuindo zero absoluto e razões interpretáveis entre valores.

\subsection{Funções de Pertinência Triangulares}

Para cada característica, definimos três conjuntos fuzzy -- "baixo", "médio" e "alto" -- representados por funções de pertinência triangulares. Uma função triangular é determinada por três parâmetros $(a, b, c)$ e definida como:

\begin{equation}
\mu_{tri}(x; a, b, c) = \begin{cases}
0 & \text{se } x \leq a \text{ ou } x \geq c \\
\frac{x - a}{b - a} & \text{se } a < x < b \\
\frac{c - x}{c - b} & \text{se } b < x < c \\
1 & \text{se } x = b
\end{cases}
\end{equation}

As funções triangulares são amplamente utilizadas em sistemas fuzzy pela simplicidade computacional e pela facilidade de interpretação~\cite{wang1997}. Embora não sejam suaves nos vértices, fornecem aproximações satisfatórias para muitos problemas práticos.

\subsection{Determinação Orientada a Dados dos Parâmetros}

Ao invés de definir parâmetros manualmente, utilizamos uma abordagem \textbf{orientada por dados} baseada em quantis da distribuição observada dos dados de treinamento. Para cada característica $f_i$, calculamos:

\begin{itemize}
    \item Percentil 0\%: $q_0 = \min(f_i)$
    \item Percentil 33\%: $q_{33}$
    \item Percentil 50\%: $q_{50}$ (mediana)
    \item Percentil 66\%: $q_{66}$
    \item Percentil 100\%: $q_{100} = \max(f_i)$
\end{itemize}

As funções de pertinência são então definidas como:
\begin{align}
\mu_{low}(x) &= \mu_{tri}(x; q_0, q_{33}, q_{50}) \\
\mu_{medium}(x) &= \mu_{tri}(x; q_{33}, q_{50}, q_{66}) \\
\mu_{high}(x) &= \mu_{tri}(x; q_{50}, q_{66}, q_{100})
\end{align}

Esta abordagem garante que as funções de pertinência reflitam a distribuição empírica dos dados, adaptando-se automaticamente às características de cada métrica.

\subsection{Orientação e Regras Fuzzy}

Para determinar se valores altos ou baixos de uma característica indicam texto autoral, comparamos as medianas dos dois grupos (autoral e LLM):

\begin{itemize}
    \item Se $\text{mediana}_{\text{autoral}}(f_i) > \text{mediana}_{\text{LLM}}(f_i)$, a orientação é \textbf{direta}: valores altos $\to$ autoral
    \item Caso contrário, a orientação é \textbf{inversa}: valores baixos $\to$ autoral
\end{itemize}

Cada característica contribui com um ``voto'' para as hipóteses autoral ou LLM baseado no grau de pertinência. Por exemplo, para uma característica de orientação direta:
\begin{align}
\text{voto}_{\text{autoral}} &= \mu_{high}(x) + 0.5 \cdot \mu_{medium}(x) \\
\text{voto}_{\text{LLM}} &= \mu_{low}(x) + 0.5 \cdot \mu_{medium}(x)
\end{align}

Para orientação inversa, os papéis de ``high'' e ``low'' são invertidos. A pertinência média ($\mu_{medium}$) contribui igualmente para ambas as classes, refletindo incerteza.

\subsection{Sistema de Inferência Fuzzy (Takagi-Sugeno de Ordem Zero)}

O sistema de inferência fuzzy implementado segue o modelo \textbf{Takagi-Sugeno de ordem zero}~\cite{takagi1985}, no qual as consequências das regras são constantes (não funções lineares). Este modelo é adequado para classificação binária e computacionalmente eficiente.

\subsubsection{Estrutura das Regras Fuzzy}

O sistema é composto por regras do tipo:

\begin{equation}
\text{SE } x_i \text{ é } A_{ij} \text{ ENTÃO } y = c_k
\end{equation}

onde $x_i$ é a $i$-ésima característica estilométrica, $A_{ij}$ é um conjunto fuzzy (baixo, médio, alto), e $c_k \in \{0, 1\}$ é a classe consequente (0 = autoral, 1 = LLM).

\subsubsection{Agregação de Votos}

Para classificar um texto com características $(x_1, x_2, \ldots, x_{10})$, agregamos os votos de todas as características por média aritmética simples:

\begin{align}
S_{\text{autoral}} &= \frac{1}{10} \sum_{i=1}^{10} \text{voto}_{\text{autoral}}^{(i)} \\
S_{\text{LLM}} &= \frac{1}{10} \sum_{i=1}^{10} \text{voto}_{\text{LLM}}^{(i)}
\end{align}

A média aritmética é um operador de agregação linear, interpretável e robusto. Pesos uniformes ($w_i = 1/10$) garantem que todas as características contribuam igualmente, evitando sobre-ajuste (overfitting) e mantendo a simplicidade do modelo.

\subsubsection{Normalização e Probabilidades de Saída}

Os scores são normalizados para fornecer probabilidades interpretáveis:

\begin{equation}
P(\text{autoral}) = \frac{S_{\text{autoral}}}{S_{\text{autoral}} + S_{\text{LLM}}}, \quad P(\text{LLM}) = \frac{S_{\text{LLM}}}{S_{\text{autoral}} + S_{\text{LLM}}}
\end{equation}

A classe predita é aquela com maior probabilidade: $\hat{y} = \arg\max\{P(\text{autoral}), P(\text{LLM})\}$.

Esta normalização garante que $P(\text{autoral}) + P(\text{LLM}) = 1$ e $P(c) \in [0, 1]$, satisfazendo os axiomas de probabilidade.

\subsubsection{Complexidade Computacional}

A complexidade de tempo para classificar um texto é $O(n \cdot m)$, onde $n = 10$ é o número de características e $m = 3$ é o número de conjuntos fuzzy por característica. Como $n$ e $m$ são constantes pequenas, a classificação é extremamente eficiente ($O(1)$ na prática), exigindo apenas 30 avaliações de funções de pertinência triangulares.

Esta eficiência contrasta com métodos baseados em redes neurais ou gradient boosting, que requerem multiplicações matriciais ou avaliações de árvores profundas. A simplicidade do modelo fuzzy o torna adequado para aplicações em tempo real e dispositivos com recursos limitados.

\subsection{Validação Cruzada Estratificada e Métricas de Avaliação}

O classificador fuzzy é avaliado usando \textbf{validação cruzada estratificada de 5 partições} (5-fold stratified cross-validation), a mesma estratégia empregada nos modelos estatísticos. A estratificação garante que cada partição mantém a proporção de 50\%/50\% entre classes, evitando viés de avaliação.

\subsubsection{Protocolo de Validação}

Para cada uma das 5 partições (folds):

\begin{enumerate}
    \item \textbf{Separação treino/teste}: 80\% dos dados são destinados ao treinamento, 20\% ao teste
    \item \textbf{Ajuste de parâmetros}: as funções de pertinência são determinadas no conjunto de treinamento através dos quantis (33\%, 50\%, 66\%)
    \item \textbf{Determinação de orientação}: a orientação (direta/inversa) de cada característica é estabelecida comparando as medianas dos dois grupos no conjunto de treinamento
    \item \textbf{Classificação}: predições são realizadas no conjunto de teste (nunca visto durante o ajuste)
    \item \textbf{Cálculo de métricas}: ROC AUC e Precisão Média (Average Precision) são computadas
\end{enumerate}

\subsubsection{Métricas de Desempenho}

As métricas reportadas são:

\begin{itemize}
    \item \textbf{ROC AUC} (Area Under the Receiver Operating Characteristic Curve): mede a capacidade discriminativa do classificador, independente do limiar de decisão. Varia de 0 a 1, onde 0.5 indica desempenho aleatório e 1.0 indica discriminação perfeita~\cite{fawcett2006}.
    \item \textbf{Precisão Média} (Average Precision): resumo da curva precisão-revocação, útil para datasets balanceados.
    \item \textbf{Desvio Padrão}: medida de dispersão dos resultados entre as 5 partições, indicando a estabilidade do modelo.
\end{itemize}

Reportamos a média e o desvio padrão de AUC ao longo das 5 partições. A implementação foi realizada no módulo \texttt{src/fuzzy.py}, com avaliação via \texttt{src/evaluate\_fuzzy.py}, utilizando a biblioteca scikit-learn~\cite{scikit-learn} para cálculo de métricas.

\subsection{Robustez e Vantagens da Abordagem Fuzzy}

A abordagem fuzzy apresenta três vantagens principais em relação a métodos estatísticos complexos: \textbf{interpretabilidade total}, \textbf{robustez superior} e \textbf{eficiência computacional}.

\subsubsection{Interpretabilidade}

A principal vantagem do classificador fuzzy é a \textbf{interpretabilidade completa}: os graus de pertinência e as regras de inferência podem ser inspecionados para compreender \textit{por que} um texto foi classificado como autoral ou LLM. Esta transparência permite:

\begin{itemize}
    \item \textbf{Auditoria}: identificar quais características contribuíram mais para a decisão
    \item \textbf{Análise qualitativa}: verificar quão típico de texto autoral ou de LLM um texto é em cada dimensão estilométrica
    \item \textbf{Detecção de incerteza}: casos com alto $\mu_{medium}$ em várias características indicam textos ambíguos ou fronteiriços
    \item \textbf{Validação especializada}: linguistas podem verificar se as regras fuzzy capturam intuições válidas sobre estilo
\end{itemize}

Esta transparência contrasta fortemente com modelos de caixa-preta (redes neurais profundas, gradient boosting), que não permitem inspeção direta do processo decisório.

\subsubsection{Robustez a Valores Extremos}

O uso de \textbf{quantis (estatísticas de ordem)} para determinar os parâmetros das funções de pertinência confere ao modelo fuzzy \textbf{resistência a valores extremos} (outliers)~\cite{wilcox2012}. Quantis são estatísticas robustas que não são afetadas por observações extremas, ao contrário de médias e desvios padrão.

Esta propriedade resulta em \textbf{estabilidade excepcional}: enquanto métodos paramétricos (Regressão Logística, LDA) apresentam desvio padrão de AUC na ordem de $\pm 0.10\%$ a $\pm 0.15\%$, o classificador fuzzy atinge variância 3–4 vezes menor ($\pm 0.04\%$), conforme demonstrado nos resultados.

\subsubsection{Custo de Oportunidade (Trade-off Interpretabilidade vs. Acurácia)}

A escolha da abordagem fuzzy implica um \textbf{custo de oportunidade}: o desempenho preditivo (AUC $\approx$ 89\%) é ligeiramente inferior ao de métodos estatísticos complexos (Regressão Logística com AUC $\approx$ 97\%). Esta diferença de aproximadamente 8 pontos percentuais representa o \textit{preço} pago pela obtenção de:

\begin{enumerate}
    \item Interpretabilidade total (explicabilidade de cada decisão)
    \item Robustez superior (menor variância, maior estabilidade)
    \item Eficiência computacional (complexidade $O(1)$)
\end{enumerate}

Este trade-off é análogo à escolha entre um modelo de regressão linear (interpretável, menos flexível) e uma rede neural profunda (alta capacidade, caixa-preta). Em contextos onde a \textbf{explicabilidade} é crítica -- como detecção de plágio acadêmico, auditoria de integridade científica, ou sistemas de suporte à decisão educacional -- o custo de 8 pontos percentuais é justificável e aceitável.

\subsubsection{Incorporação de Conhecimento Especializado}

Embora neste trabalho tenha-se optado pela determinação automática de parâmetros via quantis (abordagem orientada a dados), a abordagem fuzzy permite a incorporação de \textbf{conhecimento linguístico especializado} na construção das funções de pertinência. Linguistas e estilometristas podem ajustar os parâmetros $(a, b, c)$ manualmente para refletir intuições sobre estilo, complementando a evidência empírica com conhecimento teórico -- uma flexibilidade não disponível em métodos puramente estatísticos.
