# Joint Analysis of Stylometric Features using Statistical and Fuzzy Methods

This repository contains the scaffolding for two complementary master‐level research projects
that analyse textual data from humans and large language models (LLMs).  Both papers are
designed to be completed in a single week.  The first paper applies classical probability and
statistical methods (descriptive statistics, non‑parametric tests, PCA, LDA and logistic
regression).  The second paper applies fuzzy set theory and fuzzy logic to the same set of
features to explore approximate reasoning.  The two projects share the same dataset and
feature extraction pipeline to minimise duplication of effort.

## Directory structure

```
joint-analysis/
├── data/
│   ├── raw/             # raw corpora (e.g. `corpus.csv` with columns: text, label, topic)
│   └── processed/       # extracted feature tables
├── notebooks/
│   ├── 0_EDA.ipynb      # exploratory data analysis (common)
│   ├── 1_tests.ipynb    # statistical tests (Mann‑Whitney, Cliff’s δ, FDR) for paper_stat
│   ├── 2_multivar.ipynb # PCA, LDA, logistic regression for paper_stat
│   └── 3_fuzzy.ipynb    # fuzzy membership analysis and inference for paper_fuzzy
├── src/
│   ├── __init__.py
│   ├── features.py      # feature extraction functions for both projects
│   ├── tests.py         # statistical tests and effect size calculations (paper_stat)
│   ├── models.py        # PCA, LDA, logistic regression, cross‑validation (paper_stat)
│   └── fuzzy.py         # fuzzy membership functions and inference system (paper_fuzzy)
├── paper_stat/
│   ├── main.tex         # LaTeX file for the statistics paper
│   ├── sections/
│   │   ├── intro.tex
│   │   ├── methods.tex
│   │   ├── results.tex
│   │   ├── discussion.tex
│   │   └── conclusion.tex
│   └── refs.bib         # bibliography for the statistics paper
├── paper_fuzzy/
│   ├── main.tex         # LaTeX file for the fuzzy logic paper
│   ├── sections/
│   │   ├── intro.tex
│   │   ├── methods.tex
│   │   ├── results.tex
│   │   ├── discussion.tex
│   │   └── conclusion.tex
│   └── refs.bib         # bibliography for the fuzzy logic paper
└── requirements.txt     # optional list of Python dependencies
```

## Getting started

1. **Install dependencies.**  Create a virtual environment and install packages listed in
   `requirements.txt`.  At minimum you will need `pandas`, `numpy`, `scikit‑learn` and
   `matplotlib`.  If you wish to run the notebooks you may also need `jupyter` and
   `scipy`.

   ```bash
   python -m venv .venv
   source .venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Prepare the dataset.**  Place your corpus in `data/raw/` as a CSV file named
   `corpus.csv` with at least three columns:

   - `text`: the raw text of the sample
   - `label`: either `human` or `llm` (for classification)
   - `topic`: optional categorical label used for cross‑validation splits

3. **Extract features.**  Run the feature extraction script to compute stylometric metrics:

   ```bash
   python -m src.features --input data/raw/corpus.csv --output data/processed/features.csv
   ```

4. **Run statistical analyses.**  Use the notebooks in `notebooks/` to perform the
   exploratory analysis, apply non‑parametric tests and build PCA/LDA/logistic models.

5. **Run fuzzy analysis.**  Use the notebook `notebooks/3_fuzzy.ipynb` together with
   `src/fuzzy.py` to define membership functions, build a fuzzy inference system and
   evaluate its performance on the same features.

6. **Optional fuzzy evaluation via CLI.**  The module `src/evaluate_fuzzy.py` provides
   a command‑line interface to run cross‑validation for the fuzzy classifier and
   save ROC/PR metrics.  Example usage:

   ```bash
   python -m src.evaluate_fuzzy --features data/processed/features.csv --label-col label \
       --topic-col topic --pos-label human --neg-label llm --n-splits 5 \
       --roc-out fuzzy_roc.pkl --pr-out fuzzy_pr.pkl
   ```
   The resulting pickle files can be inspected to plot ROC and precision–recall curves
   in a notebook or script.

6. **Write papers.**  The `paper_stat/` and `paper_fuzzy/` directories contain LaTeX
   templates with pre‑created sections.  Fill in the text, include figures and tables
   generated by your notebooks, and compile with `pdflatex` and `bibtex`.

## Joint schedule for a one‑week sprint

Both papers share the same raw data and feature extraction.  Follow this intensive
schedule to complete both manuscripts within seven days:

| Day | Activities | Deliverables |
|----:|-----------|--------------|
| **D1** | Acquire/verify the corpus, familiarise yourself with the scope of both projects.  Extract features using `src/features.py`.  Begin reading relevant chapters from the recommended books (statistical methods and fuzzy logic) and recent literature. | `data/processed/features.csv`, list of papers/books for references. |
| **D2** | Perform exploratory data analysis in `0_EDA.ipynb`: distributions of features, correlations and basic differences between human and LLM texts.  Draft the introduction sections for both papers. | Notebook with descriptive graphs; first draft of `paper_stat/sections/intro.tex` and `paper_fuzzy/sections/intro.tex`. |
| **D3** | Apply non‑parametric tests (Mann–Whitney U, Cliff’s δ, FDR) and compute size of effects using `notebooks/1_tests.ipynb`.  Start writing `methods.tex` for the statistics paper. | Test results table, description of methodology. |
| **D4** | Build multivariate models: PCA for visualisation, LDA and logistic regression for classification (`2_multivar.ipynb`).  Document results and interpretations. | Figures (PCA plots, ROC curves) and draft of `paper_stat/sections/results.tex` and `discussion.tex`. |
| **D5** | Design membership functions using quantiles of the features.  Implement a fuzzy inference system in `src/fuzzy.py` (or update it) and evaluate its performance (`3_fuzzy.ipynb`).  Outline `methods.tex` for the fuzzy paper. | Fuzzy membership plots; confusion matrix; methodology section text. |
| **D6** | Perform robustness analysis for both methods (ablation of features, alternative inference strategies).  Write `results.tex` and `discussion.tex` for the fuzzy paper. | Comparative tables, discussion notes. |
| **D7** | Finalise both manuscripts: write conclusions, polish language, generate final figures and tables, format references in `refs.bib`.  Compile PDFs and proofread. | `paper_stat/main.pdf`, `paper_fuzzy/main.pdf`, updated `refs.bib` files. |

By sharing the feature extraction and EDA between the two projects you can substantially
reduce duplicated effort.  Throughout the week, continuously update both LaTeX documents
as soon as new results become available.